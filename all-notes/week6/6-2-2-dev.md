# Fork 4 repositories

# Start DB locally

Start the PostgreSQL in a Docker container. First create a volume: `docker volume create localdb`

In the DB app's folder, run: `./local-run/postgres-start.ps1` - PostgreSQL should start.

Check the script - similar to what we had for Docker Compose, but it has some resource limitation turned on.

# Start the DB application locally

DB app's folder: `./local-run/app-start.ps1` This will build, test and run the application locally 

It connects to the DB, with Java system properties.

Open the Postman project, or use copy the OpenApi descriptor and paste it here: https://editor-next.swagger.io/

Test both endpoints
* first the GET one, will return an empty array
* call the creator endpoint
* call the GET recent again, will return the previously sent message

# Start the API application locally

API app's folder: `./local-run/app-start.ps1` This will build, test and run the application locally 

It connects to the DB application with Java system properties.

Again, import into Postman, or copy-paste into Swagger, and test:
* local GET
* local POST
* store endpoint

# Start integrated environment

Create a new namespace: `kubectl create namespace cubix`

In deploy-postgres repository we can see there is only one values.yaml file. It does not have a password - that should not be stored in git.

The starting command can be found in the README, there is not much surpise.

Put in a password to the command (and remember it), and run it. Check the logs: `kubectl logs statefulset/postgresql -n cubix`

In deploy-apps, there is a Helm Chart, and two values.yaml file for each application.

Check for the image name in your forked API and DB application's GitHub page, and put it in the corresponding values.yaml files.

Start the applications with the help of the README file, put in the DB password, and run through the Chart and values.yaml files: it is similar what we had before.

Check whether they are running: `kubectl get pods -n cubix`

The API application can be called through the Ingress:
* on OpenAPI switch to Kubernetes endpoint and disable Mixed Block
* in Bruno, select the Kubernetes environment
* in Postman replace the variable: http://application.cubix.localhost:8080

Test the endpoints again.

# Automate deployment

We will do a Continous Deployment. Delete and re-create the namespace: `kubectl delete namespace cubix` and `kubectl create namespace cubix`

Enter our deploy-postgres repository on GitHub and check for running jobs. If there are, stop them.

Two settings must be made: retrieve the password and allowing GitHub Actions to reach our local machine. Open Settings/Secrets and Variables/Actions.

There are environment and repository secrets, the latter is good for us. The key must be `POSTGRESQL_PASSWORD`, 
the value does not matter but remember for it (can not be read later).

For deploying we will use a self-hosted runner. An agent will be started on our local machine, that will connect to the Actions.
If Actions receive an event, it will send it to our machine, and it can run processes on our machine.

Note that it will use kubectl on our machine, so we do not need authentication - if the kubectl would run on a remote machine that would also be a step.

Actions/Runners/New Self-Hosted Runner

A Runner was already downloaded, it just has to be set up per the instructions. Not recommended to start as a service. Start by hand.

On Actions, start Local Deployment to Kind. In the Runner's terminal we can see, that a job started. Logs can be read on GitHub.

We can see what the result is, if OK, also check logs for the DB.

Do the same for the deploy-apps (password must be remembered). Here, instead of manual starting, push the image change.
This triggered the deployment!

Check the application Pods.

Finally check the API app's endpoints
